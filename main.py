#!/usr/bin/python

import analyser
import argparse
import config
import crawler
import extractor
import net

parser = argparse.ArgumentParser(description="Crawl CVE records")
parser.add_argument("--gusername", type=str, help="github username")
parser.add_argument("--gpassword", type=str, help="github password")
parser.add_argument("--updatenvd", type=bool, help="update nvd feeds", default=False)
parser.add_argument("--crawl", type=bool, help="crawl", default=False)
parser.add_argument("--dump-commits", type=bool, help="dump commit hashes", default=False)
parser.parse_args(namespace=config)
if config.gusername and config.gpassword:
    net.set_github_auth()
else:
    print "Warning: github auth not set. There'll be a limit of requests/hour"

if config.updatenvd:
    crawler.crawl_nist_feed()
if config.crawl:
    crawler.crawl_linux_kernel_cves()
    crawler.crawl_android_cve_checker(local=False)
    crawler.crawl_django()
    crawler.crawl_debian_security(local=False)
    crawler.crawl_vuln_db(local=True)
    crawler.crawl_debian_fake_names()
if config.dump_commits:
    extractor.dump_commits()

# analyser.cluster_nist_urls()
