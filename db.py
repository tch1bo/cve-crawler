#!/usr/bin/python

import config
import sqlalchemy as sa
from sqlalchemy import bindparam
from sqlalchemy.orm import sessionmaker, scoped_session
import time

# engine = sa.create_engine("sqlite:///data/db.sqlite3")
engine = sa.create_engine("mysql://root:@localhost/crawler")
Session = sessionmaker(bind=engine, autoflush=False)
global_session = Session()
connection = engine.connect()

# TODO: change counter and stats module.

class Query:
    def __hash__(self):
        return hash(self.to_tuple())

    def __cmp__(self, other):
        return cmp(self.to_tuple(), other.to_tuple())

class InsertQuery(Query):
    def __init__(self, table, **kwargs):
        self.table = table
        self.params = kwargs

    def to_tuple(self):
        params_tuples_list = sorted(self.params.items())
        return tuple([self.table.__tablename__] + params_tuples_list)

    @staticmethod
    def process_func(queries):
        tables = set([q.table for q in queries])
        for t in tables:
            table_queries = [x for x in queries if x.table == t]
            find_or_add_objects(t, table_queries, need_ids=True)


class ConnectQuery(Query):
    def __init__(self, table, left_unique_value, right_unique_value):
        self.table = table
        self.left_unique_value = left_unique_value
        self.right_unique_value = right_unique_value

    def to_tuple(self):
        return (self.table.name, self.left_unique_value, self.right_unique_value)

    @staticmethod
    def process_func(queries):
        mtm_tables = set([q.table for q in queries])
        # Preindex data.
        index = {}
        def index_table(table):
            get_all_objects = lambda: global_session.query(table).all()
            get_unique_field = lambda x: getattr(x, table.unique_field)
            index.setdefault(table,
                    {get_unique_field(x): x for x in get_all_objects()})

        for mtmt in mtm_tables:
            index_table(mtmt.left_table)
            index_table(mtmt.right_table)
            table_queries = [x for x in queries if x.table == mtmt]
            ids = []
            for q in table_queries:
                left = index[mtmt.left_table][q.left_unique_value]
                right = index[mtmt.right_table][q.right_unique_value]
                ids += [(left.id, right.id)]
            find_or_add_for_mtm_table(mtmt, ids)

class UpdateQuery(Query):
    pass

""" A special case of UpdateQuery for updating tags on cves and non_cves. """
class UpdateTagQuery(Query):
    def __init__(self, table, unique_value, tags):
        self.table = table
        self.unique_value = unique_value
        self.tags = tags

    @staticmethod
    def process_func(queries):
        tables = set([q.table for q in queries])
        for t in tables:
            table_queries = [x for x in queries if x.table == t]
            index = {getattr(obj, t.unique_field): obj
                    for obj in global_session.query(t).all()}
            changes = []
            for q in queries:
                obj = index[q.unique_value]
                new_tag = obj.add_tags(q.tags)
                changes.append((q.unique_value, new_tag))
            stmt = t.__table__.update().\
                where(getattr(t, t.unique_field) == bindparam("unique_field")).\
                values(tag=bindparam("new_tag"))
            global_session.execute(stmt,
                [{"unique_field": c[0], "new_tag": c[1]} for c in changes])
            global_session.commit()

    def to_tuple(self):
        return (self.table.__tablename__, self.unique_value) + tuple(self.tags)

def debug_print(msg):
    if config.DB_VERBOSE:
        print msg

def process_queries(all_queries):
    query_classes = [
            # Order of classes here is important.
            InsertQuery,
            ConnectQuery,
            # UpdateQuery,
            UpdateTagQuery,
    ]
    for C in query_classes:
        queries = [q for q in all_queries if q.__class__ == C]
        C.process_func(queries)

"""
    Queries the database and returns found objects.

    Arguments:
        table - the ORM class representing the needed table.
        list_of_queries - list of InsertQuery objects.
    Returns:
        A dict{query: obj/False}, where keys are queries and values are either
        the first object matching the query or False if no object can be found.

    Comments:
        1. Apparently, executing many sql queries is a bottleneck. This is why
        we query all objects and filter them manually in code.
        2. For this function to work, table should have a "unique_field" field
        defined.
"""
def find_objects(table, list_of_queries):
    def comp_func(obj, query):
        for k, v in query.params.iteritems():
            if getattr(obj, k) != v:
                return False
        return True

    # Get all rows from db.
    all_objects_list = global_session.query(table).all()
    all_objects_dict = {}
    for x in all_objects_list:
        field = getattr(x, table.unique_field)
        # Arrange them in a map, where value of the field "unique_field" is the key.
        all_objects_dict.setdefault(field, []).append(x)

    debug_print("Searching for objects in table: {0}".format(table.__tablename__))
    if config.DB_VERBOSE:
        bar = misc.KnownLengthBar(maxval=len(list_of_queries), parallel=False)
        list_of_queries = bar(list_of_queries)
    res = {}
    found_count = 0
    for query in list_of_queries:
        res[query] = False
        field = query.params[table.unique_field]
        if all_objects_dict.get(field) is None:
            continue
        for x in all_objects_dict[field]:
            if comp_func(x, query):
                found_count += 1
                res[query] = x
                break
    debug_print("Search done. Found {0}/{1} objects".format(found_count, len(list_of_queries)))
    return res

"""
    Stores objects, which are not in the db.

    Arguments:
        table - see the description in find_objects.
        list_of_queries - see the description in find_objects.
        need_ids - flag specifying if the returned objects should have their
            ids set.

    Returns:
        Returns the dict{query: obj}, where obj is either found in the db
        (see find_objects) or newly created.
"""
def find_or_add_objects(table, list_of_queries, need_ids=False):
    debug_print('=' * 80)
    debug_print("Finding/adding {0} objects to the table: {1}".format(
            len(list_of_queries), table.__tablename__))
    # See the comment for find_or_add_object_orm.
    search_res = find_objects(table, list_of_queries)

    # key - the query, for which the corresponding object was not found in db.
    # value - the position of x in list_of_queries.
    not_found = {x: i for i, x in enumerate(list_of_queries) if not search_res[x]}

    debug_print("Have to add {0}/{1} objects".format(len(not_found),
            len(list_of_queries)))

    # Same, but key is an object built from the args given in query.
    objects = {table(**x.params): i for x, i in not_found.iteritems()}
    global_session.bulk_save_objects(objects.keys())
    global_session.commit()

    for x, i in objects.iteritems():
        search_res[list_of_queries[i]] = x
    if need_ids and len(not_found) > 0:
        # Apparently session.commit() does not update the ids of newly created
        # objects. To deal with it, we repeat the search step (it should work
        # fast enough).
        debug_print("Repeating the find step to populate object ids")
        debug_print('=' * 80)
        return find_objects(table, list_of_queries)
    debug_print('=' * 80)
    return search_res

"""
    Works similar to find_or_add_objects, but for many-to-many (mtm) tables
    instead of ORM objects.

    Arguments:
        mtm_table - the mtm table.
        list_of_ids - list of tuples of form: (left_id, right_id)

    Returns:
        A tuple x, where:
            x[0] = number of left_ids inserted,
            x[1] = number of right_ids inserted.
"""
def find_or_add_for_mtm_table(mtm_table, list_of_ids):
    debug_print('=' * 80)
    rows = set([tuple(x) for x in global_session.execute(mtm_table.select()).fetchall()])
    not_found = [x for x in list_of_ids if (x[0], x[1]) not in rows]
    debug_print("Have to add {0}/{1} rows to table".format(len(not_found), len(list_of_ids)))

    left_id_key = list(mtm_table.columns)[0].name
    right_id_key = list(mtm_table.columns)[1].name

    global_session.execute(mtm_table.insert(),
            [{left_id_key: x[0], right_id_key: x[1]} for x in not_found])
    global_session.commit()

    debug_print('=' * 80)
    new_first_ids_count = len(set([x[0] for x in not_found]))
    new_second_ids_count = len(set([x[1] for x in not_found]))
    return (new_first_ids_count, new_second_ids_count)

def find_object_orm(obj_class, session, **kwargs):
    q = session.query(obj_class)
    for k, v in kwargs.iteritems():
        q = q.filter(getattr(obj_class, k) == v)
    return q.first()

def find_or_add_object_orm(obj_class, session, **kwargs):
    # In multithreaded environment there might be a race condition, which
    # would violate the uniqueness property and thus raise an exception here.
    while True:
        obj = find_object_orm(obj_class, session, **kwargs)
        if obj:
            return obj
        obj = obj_class(**kwargs)
        try:
            session.add(obj)
            session.commit()
        except:
            session.rollback()
            continue
        break
    return obj
